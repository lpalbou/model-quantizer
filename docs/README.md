# Model Quantizer Documentation

Welcome to the Model Quantizer documentation. This directory contains comprehensive guides and resources to help you quantize, benchmark, and deploy Hugging Face models.

## Available Documentation

### General Guides

- [General Model Quantization Guide](general_guide.md): A comprehensive guide to quantizing any Hugging Face model using the Model Quantizer tool.
- [Troubleshooting Guide](troubleshooting.md): Solutions for common issues encountered when quantizing models.
- [Benchmarking Guide](benchmarking.md): How to benchmark quantized models to evaluate performance, memory usage, and output quality.
- [Publishing Guide](publishing_guide.md): Instructions for publishing your quantized models to the Hugging Face Hub.

### Model-Specific Guides

- [Phi-4-Mini Quantization Guide](phi4_mini.md): Specific guide for quantizing the Microsoft Phi-4-mini-instruct model.

## Getting Started

If you're new to model quantization, we recommend starting with the [General Model Quantization Guide](general_guide.md), which provides an overview of the quantization process and available methods.

For specific models, check if there's a dedicated guide (like the [Phi-4-Mini Quantization Guide](phi4_mini.md)) that provides optimized settings and recommendations.

## Examples

For practical examples, see the [examples](../examples) directory, which contains scripts for:

- Quantizing models
- Using quantized models
- Benchmarking performance
- Visualizing results
- Comparing memory usage

## Contributing

If you'd like to contribute to the documentation:

1. Fork the repository
2. Create a new branch for your changes
3. Add or update documentation files
4. Submit a pull request

We welcome improvements to existing guides and new model-specific guides.

## Support

If you encounter issues not covered in the [Troubleshooting Guide](troubleshooting.md), please open an issue on the GitHub repository. 